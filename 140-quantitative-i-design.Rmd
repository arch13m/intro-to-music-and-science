# Quantitative (I): Design

```{r, include = FALSE}
library(tidyverse)
library(ggpubr)
theme_set(theme_pubr())
knitr::opts_chunk$set(echo = FALSE)

```

Quantitative methods, at their core, are all about characterising two things:

(a) distributions of variables;

(b) relationships between variables.

These relationships can be summarised either numerically (e.g. using tables) or graphically (e.g. using plots). For example, we might study how fuel efficiency (measured in miles per gallon) is distributed in a collection of cars:

```{r}
mtcars |> 
  ggplot(aes(mpg)) + 
  geom_histogram(bins = 20) +
  scale_x_continuous("Fuel efficiency (miles per gallon)") + 
  scale_y_continuous("Count")
```

We might follow that up by studying how fuel efficiency relates to the car engine's horsepower:

```{r}
mtcars |> 
  ggplot(aes(hp, mpg)) + 
  geom_point() + 
  scale_x_continuous("Engine horsepower") +
  scale_y_continuous("Fuel efficiency (miles per gallon)") 
```

It feels very natural to speak about car engines in these numeric constructs such as miles per gallon and horsepower, and to quantify relationships between them using data plots. In contrast, it is less obvious how to construct equivalent numeric constructs for human psychology, where many of the relevant concepts (e.g. personality, attention, consciousness) are hard to define and even harder to measure. This task of defining appropriate variables is one of the key challenges of psychology research.

## Defining variables

### Scientific variables

In scientific contexts, a variable may be defined as a measurement with a well-defined set of potential values. One example might be age (in years), corresponding to a number ranging typically between 0 and 100. Another example might be nationality, which might take values such as French, German, or Italian.

Variables come in many forms, and these forms have important implications for how you design an experiment as well as how you analyse the resulting data. Here are several types of variable, as commonly defined in methods textbooks:

-   **Categorical variables (a.k.a. nominal variables).** These take one of a finite set of values, with these values having no intrinsic ordering. An example might be nationality, which could take values such as French, German, and Indian. A special kind of categorical variable is a **binary variable (a.k.a. dichotomous variable)**: this is simply a categorical variable with only two possible values, which comes up for example in True/False questions.

-   **Ordinal variables.** Like categorical variables, these take one of a finite set of values, but unlike categorical variables, these values have an intrinsic order. An example of an ordinal variable might be a participant's response to the following question: "How much do you like jazz music?" where the participant has to choose from four options labelled 1-4:

    1.  Not at all;

    2.  A little;

    3.  A lot;

    4.  Very much.

-   **Continuous variables**. These are variables that take numeric values within a continuous range. A truly continuous variable should be able to be specified to an arbitrary degree of precision: for example, we might say that the temperature is 45.832 degrees Centigrade. There are two main types of continuous variable:

    -   **Interval variables**. A variable is an 'interval' variable if (and only if) addition and subtraction are 'meaningful' operations. For example, the time of day is an interval variable, because it makes sense to say 'ten minutes after' (addition) or 'five minutes before' (subtraction) a given time.

    -   **Ratio variables.** These are like interval variables, but they have an additional property: multiplication is also a meaningful operation. Money is an example of a ratio variable, because it makes sense to say that Anna (for example) has twice as much money as Bob. Temperature in Centigrade is meanwhile **not** a ratio variable, because it doesn't make sense to say that 20°C is 20 times as hot as 1°C (at least, not if we listen to our physics teacher).

It is worth making a few notes at this point:

-   In practice, most analysis methods used in psychology do not differentiate between interval and ratio variables, so it is rarely worth losing much sleep over this distinction.

-   There are nonetheless often grey areas where different variable categories overlap. For example, a student might take a multiple-choice exam with a 100 questions, and therefore possible marks would be 1, 2, 3, ..., 99, or 100. This is technically not a fully continuous variable, because the set of possible marks is finite, and it is not possible to get 'in-between' marks such as 22.5 or 33.7. However, in many situations (e.g. data analysis) it will be useful here to treat the variable as if it is indeed continuous.

-   A particularly debated area is multiple-choice questionnaires, where participants have to choose from multiple numbered options arranged in a scale, for example:

    1.  Not at all;

    2.  A little;

    3.  A lot;

    4.  Very much.

    Some might argue that this variable is ordinal, because it's not obvious that addition and subtraction make sense here. Others might say that participants naturally understand that the scale is meant to be interpreted as an interval scale, and hence respond in a manner that is consistent with that. This question is not really resolved in the literature, but it is fairly accepted practice in these scenarios to pretend like the variable is an interval variable.

### Psychological variables

Psychological studies can include various kinds of variables. These can be organised more-or-less into the following categories:

1.  Experimental condition;
2.  Physical behaviours;
3.  (Neuro-)physiological responses;
4.  Latent traits;
5.  Demographics;

Let's discuss each of these in turn.

#### Experimental condition

TODO

#### Physical behaviours

A *behaviour* is something that a person does with their physical body. This could be something specific to the laboratory context (e.g. pressing a green button on a response pad), but it could also mean something in everyday life, for example buying a particular CD in a shop.

Psychoacoustic experiments often produce variables in this category. For example, we might play a participant two tones, and ask them to press 'Button A' if the first one was the highest pitch, and 'Button B' if the second tone was the highest pitch. We might then end up with a dataset like the following, where the 'Response' column is the behavioural variable:

| Participant ID | Frequency 1 (Hz) | Frequency 2 (Hz) | Response |
|----------------|------------------|------------------|----------|
| 1              | 440              | 460              | B        |
| 1              | 420              | 421              | A        |
| 1              | 375              | 400              | B        |
| ...            | ...              | ...              | ...      |

Behavioural variables also come up in studies of everyday musical behaviours. For example, a recent paper [@Park2019-kb] studied global music listening patterns as collected through the music streaming service Spotify, and identified how people in different countries listen to different kinds of music at different times of day. A dataset from such a study might look like this:

+----------------+-----------------+-----------------+-----------------------------+
| Participant ID | Date            | Time            | Musical track               |
+================+=================+=================+=============================+
| 1              | 03-01-2020      | 08:57           | 'Toxic' by Britney Spears   |
+----------------+-----------------+-----------------+-----------------------------+
| 1              | 03-01-2020      | 14:27           | 'Caravan' by Duke Ellington |
+----------------+-----------------+-----------------+-----------------------------+
| 1              | 04-01-2020      | 10:03           | 'Lingus' by Snarky Puppy    |
+----------------+-----------------+-----------------+-----------------------------+
| ...            | ...             | ...             | ...                         |
+----------------+-----------------+-----------------+-----------------------------+

Here the behavioural variable would be the musical track that the individual chose to listen to. Of course, we can get pedantic here about the extent to which an individual actively chooses to listen to a specific musical track: for example, if they've selected 'Shuffle' then Spotify will be choosing the next song for them, albeit from a limited selection. But the general point is clear, that this dataset reflects to some extent real-world decisions that the individual is making about what music to listen to.

Music psychology experiments are often particularly interested in quantifying listeners' *subjective* experiences when they listen to music: for example, the sense in which a listener finds certain sounds beautiful, or happy, or moving. Though it is difficult (impossible?) to measure subjective experiences directly, it is perfectly possible to ask the participant to describe these subjective experiences. For example, if we were interested in subjective beauty, we might ask the participant to rate the stimulus for beauty on a scale from 1 to 4, where 1 means 'not at all beautiful' and 4 means 'very beautiful'.

#### (Neuro-)physiological responses

It has been known for decades that psychological processes are ultimately mediated by the brain. Historically speaking, the brain's workings have been opaque to external observers, but recent neuroscientific techniques now give us various ways to measure aspects of brain activity. The resulting data is typically highly complex, and interpreting it is no easy task. However, the approach is appealing because it gives a real insight into how psychological processes are mediated by neural biology. Some important examples are given below:

-   *Electroencephalography (EEG)* records tiny electrical currents from the scalp that reflect firing patterns of neurons in the outer layers of the brain. EEG has a high temporal sensitivity which makes it particularly good for tracking the time course of responses to auditory stimuli. However, it is limited in its ability to localise brain activity to particular regions.

-   *Magnetoencephalography* (MEG) records faint magnetic fields that, similar to EEG, reflect firing patterns of neurons in the brain. Like EEG, MEG has a high temporal sensitivity, but it also has somewhat greater localisation abilities than EEG.

-   *Functional magnetic resonance imaging* (fMRI) measures changes in blood flow through the brain. This is useful because (as it turns out) blood flow is a reliable marker of neural activity; when a particular brain region is experiencing high neural activity, blood flow to that region will increase so as to provide more oxygen for respiration. fMRI has much better localisation capacity than EEG or MEG; however, its temporal sensitivity is much lower than either method, producing data on the granularity of seconds rather than milliseconds.

#### Latent traits

In everyday life we often speak of certain personal characteristics that are not physically measurable (e.g. height, weight) but rather reflect something less tangible. In psychology we call these characteristics *latent traits*. A fundamental challenge in psychology research is how to quantify these latent traits.

One example of a latent trait is *personality*. A prominent psychological theory of personality is the so-called *Big Five* model, which characterises personality in terms of five underlying factors:

1.  Extraversion;

2.  Agreeableness;

3.  Openness to experience;

4.  Conscientiousness;

5.  Neuroticism.

The idea is that each person's personality can be summarised (to some extent) as a collection of five scores, one for each of these five dimensions.

How do we measure these different dimensions? It's hardly as if we can take out a ruler and measure the size of different areas of the brain corresponding to these different personality traits. Even if we had a spare magnetic resonance imaging (MRI) scanner lying around with which to measure individual brain anatomy, the mapping between brain dimensions and psychological traits tends to be rather too complicated for such a procedure to be practical in most situations.

Instead, like many latent traits, we tend to assess personality using *questionnaires*. A questionnaire is simply a collection of standardised questions that we administer to a participant. Many question formats are possible, but in quantitative studies it's particularly common to administer questionnaires with numeric responses. For example, when assessing someone's personality, we might ask them the following question, sourced from the Ten Item Personality Inventory (TIPI) [@Gosling2003-bt]:

> *Please indicate the extent to which you agree with the following statement.*
>
> I see myself as: sympathetic, warm.

We could then ask the participant to give their response on a seven-point scale:

1.  Disagree strongly
2.  Disagree moderately
3.  Disagree a little
4.  Neither agree nor disagree
5.  Agree a lot
6.  Agree moderately
7.  Agree strongly

The question is designed to assess the participant's *agreeableness*. High scores (e.g. 6, 7) reflect an agreeable participant, whereas low scores (e.g. 1, 2) reflect a disagreeable participant.

A given questionnaire would typically contain multiple such questions. In the TIPI, there are ten questions in total, two for each of the five personality dimensions. The second agreeableness question looks like this:

> *Please indicate the extent to which you agree with the following statement.*
>
> I see myself as: critical, quarrelsome.

This second question is what we call a *reverse-scored* question. When we analyse data from reverse-scored questions, we interpret high numbers as a low numbers and low numbers as high numbers. In this case, participants who responded 'Disagree strongly' would receive a score of 1, whereas participants who responded 'Agree strongly' would receive a score of 7. The necessity to reverse-score the question comes from the nature of the words being used: while 'sympathetic' and 'warm' are near-synonyms of 'agreeable', 'critical' and 'quarrelsome' are near-antonyms (i.e. opposites). To get an overall agreeableness score, we could then simply average the numeric results from the first and second (reverse-scored) agreeableness questions. For example, if I wrote 'Agree moderately' to the question 'I see myself as sympathetic, warm', and 'Disagree strongly' to the question 'I see myself as critical, quarrelsome', I'd get an agreeableness score of `(6 + 1) / 2 = 3.5`.

#### Demographics

Lastly, we have demographic variables. These are generic characteristics of individuals as seen for example in a census. It is important to record at least some of these variables in order to build an approximate picture of the participant group. Some examples are given below:

-   Age

-   Gender

-   Country of birth

-   Country of residence

-   Educational level (measured e.g. in terms of the highest educational qualification received)

-   Socioeconomic status (corresponding broadly to one's income level and position within society)

Of these, age, gender, and country of residence are considered particularly essential for psychological studies; it is difficult to publish a paper that omits this information.

### Musical variables

Music psychology studies also often involve some kind of music, and often it is possible to derive useful variables from this music. Here we will consider three main categories of musical variables:

1.  Human annotations
2.  Computational annotations
3.  Other metadata

#### Human annotations

Human annotations are variables that represent human evaluations of the music, typically collected in advance of the main study itself. These annotations could come from expert musicians who are fluent in relevant music theory and terminology; for example, we could ask some expert musicians to annotate the implied harmonies for various folk melodies. Alternatively, non-expert listeners can also provide useful annotations in some cases, though typically it is necessary to get a larger number of such listeners and average over their responses in order to get reliable data. An example is given in the fictional dataset below:

| Melody ID | Tonic | Mode  |
|-----------|-------|-------|
| 1         | A     | Minor |
| 2         | F     | Major |
| 3         | G     | Major |
| ...       | ...   | ...   |

#### Computational annotations

It is also possible to generate useful variables by running musical extracts through computer algorithms. Variables extracted in such a way are typically called *features*.

There are many such algorithms out there, designed to perform all kinds of tasks. Particularly relevant are algorithms designed explicitly for the purpose of psychological modelling.

These computer algorithms can be differentiated in terms of the kind of data that they ingest. Some take so-called *symbolic* data, whereas others take *audio* data.

##### Symbolic approaches

We say that music is represented 'symbolically' when we write it down in terms of a (relatively) small set of discrete symbols. Classical score notation is an example of a symbolic notation system, with categorical representations for both rhythm (e.g. minim, dotted minim, crotchet, quaver) and pitch (e.g. C4, C#4, F5). When dealing with computers, we tend to write things as numbers where possible, so we might write the first phrase of 'Twinkle twinkle little star' as follows:

| Note ID | Pitch | Time | Duration |
|---------|-------|------|----------|
| 1       | 60    | 0    | 1        |
| 2       | 60    | 1    | 1        |
| 3       | 67    | 2    | 1        |
| 4       | 67    | 3    | 1        |
| 5       | 69    | 4    | 1        |
| 6       | 69    | 5    | 1        |
| 7       | 67    | 6    | 2        |

We then might feed this data into a collection of symbolic algorithms in order to extract some useful features for our experiment. For a simple example, suppose we run two algorithms: a key-finding algorithm and a melodic expectation algorithm. Let's further agree that we run both in a sliding-window fashion, such that the algorithm at timepoint 1 only sees data from timepoints 0 and 1, and so on.

| Note ID | Pitch | Time | Duration | Est. tonic | Est. mode | Probability |
|---------|-------|------|----------|------------|-----------|-------------|
| 1       | 60    | 0    | 1        | F          | Major     | 0.1         |
| 2       | 60    | 1    | 1        | F          | Major     | 0.3         |
| 3       | 67    | 2    | 1        | C          | Major     | 0.2         |
| 4       | 67    | 3    | 1        | C          | Major     | 0.3         |
| 5       | 69    | 4    | 1        | C          | Major     | 0.3         |
| 6       | 69    | 5    | 1        | C          | Major     | 0.4         |
| 7       | 67    | 6    | 2        | C          | Major     | 0.4         |

Here we've ended up with three computational features in our fictional dataset:

-   'Est. tonic' tells us the tonic as estimated by the key-finding algorithm. It starts off thinking that the melody is in F (with the first note being the dominant), but once it hears the third note it decides that the melody is in C after all. A well-known such algorithm is the *Krumhansl-Kessler key-finding algorithm* \[@krumhansl1990cognitive\].

-   'Est. mode' tells us the estimated mode; in our case it believes that the melody is in the major mode throughout.

-   'Probability' tells us how likely the melodic expectation algorithm believes the current note to be, taking into account what happened so far in the melody. Prominent examples of melodic expectation algorithms are Temperley's melodic expectation algorithm [@Temperley2008-tj] and Pearce's Information Dynamics Of Music (IDyOM) model [@Pearce2005-bm].

##### Audio approaches

#### Other metadata

### Levels of measurement

What kinds of variables might we have in music psychology experiments? There are many possibilities. Most can usually be categorised as either *participant variables* or *stimulus variables*.

-   **Participant variables.** These are properties of the *participant*. Many of these are personal traits that existed before the experiment, for example age, gender, prior musical training, and so on. Other of these might be variables that are determined during the experiment, for example when the experimenter assigns the participants to different experimental conditions. For example, suppose that we conduct a study on schoolchildren, investigating the effect of music lessons on intelligence; we might end up with the following table, where each row is a participant, and each column is a participant variable:

| Name   | Gender | Start age | Condition     | Start IQ | End IQ |
|--------|--------|-----------|---------------|----------|--------|
| Oliver | Male   | 12        | No lessons    | 110      | 111    |
| George | Male   | 11        | Music lessons | 105      | 110    |
| Olivia | Female | 11        | No lessons    | 99       | 98     |
| Amelia | Female | 12        | Music lessons | 103      | 104    |

: Fictional dataset illustrating different participant variables.

-   **Stimulus variables.** These are properties of a *stimulus*. A given music psychology experiment might involve many different musical stimuli, and we might be interested in how different stimuli elicit different responses from participants. Below is an excerpt from a real published dataset [@Bowling2018-hz] of 'attractiveness' ratings for musical chords, supplemented with computational analyses of these chords from a later publication [@Harrison2020-gx]:

```{r}

readRDS("input/consonance/perception-bowling.rds") %>% 
  transmute(
    # Chord = Hmisc::capitalize(name), 
    `Interval (semitones)` = map_chr(pi_chord, ~ paste(sprintf("%.2f", diff(.)), collapse = ", ")),
    # Pitches = map_chr(pi_chord, ~ paste(sprintf("%.2f", .), collapse = ", ")),
    `Attractiveness rating` = sprintf("%.2f", rating),
    Roughness = sprintf("%.2f", hutch_78_roughness),
    Harmonicity = sprintf("%.2f", har_18_harmonicity),
    Familiarity = sprintf("%.2f", - scale(har_19_corpus))
  ) %>% 
  slice(1:12) %>% 
  knitr::kable(caption = "Attractiveness ratings for dyads from @Bowling2018-hz supplemented with computational analyses from @Harrison2020-gx.")
```

### The challenge of psychological measurement

It is relatively easy to define a valid measurement process for many physical variables, for example height and weight. You can measure someone's height with a tape measure, and you can measure their weight with a weighing scale. Sure, if you're doing it properly you might have to think carefully about some subtle points of the methodology (should the height measurement include the person's hair? does it matter whether we measure the person in the morning versus the evening, or before or after a large meal?), but conceptually it is not too difficult to convince oneself of the validity of the measurement process.

In contrast, it is relatively complicated to define a valid measurement process for many psychological variables, because these variables are generally much more theoretical in their conceptualisation. Take *personality* as an example.

It's certainly quick and efficient to measure someone's personality using just 10 multiple-choice questions. The question is, though, how 'good' is the resulting measurement? In psychology we typically answer that question by thinking about two subcomponents of measurement quality: *reliability* and *construct* *validity.*

#### Reliability

A measurement instrument's *reliability* may be defined as the extent to which it produces similar measurements under similar conditions. In the context of psychological measures, this is most commonly interpreted as meaning 'if I were to measure the same person multiple times, would I get similar results?' In the context of measuring someone's height, we'd class a measuring scale as 'reliable' if it gave a similar reading if we weighed the same person twice in a row. In the context of a personality questionnaire, we might expect a reliable questionnaire to give the same participant similar scores no matter whether they take the test on a Tuesday versus a Wednesday.

Reliability is necessary but not sufficient for a measure to be a 'good' measure. What if we measure an adult's extraversion by counting how many friends they had in primary school? This measure will be highly *reliable* in the sense that this number is not going to change now that the adult has left school, so we're always going to get the same answer no matter how many times we ask the question. On the other hand, this question is clearly not a particularly 'good' measure of extraversion, because there are many other factors that can contribute to the size of someone's friendship group, for example whether they were home-schooled or not. This brings us to the following notion of *construct validity*.

#### Validity

A measurement instrument's *construct* *validity* may be defined as the extent to which it truly measures the underlying trait which it is purported to measure [@Cronbach1955-ep].

It is generally accepted that establishing construct validity requires the researcher to engage explicitly with theoretical aspects of the trait and its measurement process; in other words, construct validity *cannot* be established in a theory-free manner. This differentiates it from reliability, which can typically be established without any kind of reference to theory (e.g. by administering the same test twice to the same participants and correlating the results).

Theorising about construct validity requires the researcher to be particularly clear about two criteria:

1.  How exactly do we define the trait that we are trying to measure?

2.  How should this trait manifest in the observable world?

Different theorists have proposed different routines for establishing construct validity. There is still no real consensus on the precise procedures to carry out, though, and in practice construct validity establishment is often dealt with in a somewhat *ad hoc,* case-by-base manner.

Psychological texts often differentiate various kinds of construct validity. These represent different strategies that a researcher might use to substantiate the construct validity of a given measurement instrument. Here are several particularly important examples:

##### Concurrent validity

*Concurrent validity* is established when a new measure is shown to correlate highly with a pre-established 'gold-standard' measure. This gives us confidence that, if the old measure was valid, then the new measure is also valid, because it produces similar results. This kind of validity is useful when developing new forms of tests for new kinds of testing environments; for example, the personality questionnaire described above (the TIPI \[@Gosling2003-bt\]) was developed to replicate the results from pre-existing personality questionnaires but in a particularly short and efficient manner. However, it is not very useful when trying to establish a completely new measurement instrument, in which case there is no pre-existing reference instrument to work with.

##### Convergent validity

*Convergent validity* is established when a new measure is shown to correlate positively and substantially with certain other measures as predicted by theoretical considerations. The difference between convergent validity and concurrent validity is that these other measures are not meant to be measuring the *same* trait as the new measure; rather, they are meant to be measuring *related* traits. For example, suppose that I try to validate a new musical ability questionnaire by correlating its results with scores from a melodic dictation exercise. In general, I would expect participants with higher musical ability to score higher on the melodic dictation exercise, and so a positive correlation between the two scores would provide some support

-    **- gold-standard**

-   **Convergent validity. - correlates with things it's meant to correlate with**

-   **Discriminant validity.**

-   **Predictive validity. -- predicting future outcomes**

Unfortunately there is some discrepancy in the literature about the definitions of these different terms. This is somewhat inevitable given the fuzziness of the underlying topic. Do not worry too much about this; the important thing is that these different terms provide useful starting points for conversations about interpreting psychological measures.

#### Other kinds of psychological variables

-   Surveys

-   Behaviour (what do people do?)

    -   Reaction times

    -   Choices (gambling, music listening)

-   Neuroimaging

#### Summary: Psychological measurement is challenging

## Studying relationships between variables

What can we read into a relationship? (association, prediction, causality)

How reliable is a relationship? (inference)

How generalisable is a relationship? (generalisability)

## Measurement

## Causality

## Generalisability

## Ethics

## Examples

#### Psychological studies

#### Corpus studies

#### Acoustic studies
