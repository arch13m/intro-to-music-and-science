# Pitch perception

```{r, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(
  echo = FALSE, results = "asis"
)
source("setup.R")
```

In \@ref(foundations-of-acoustics) we saw various forms of idealised waves: the sine wave, the sawtooth wave, and the square wave. These waves all differ in shape, but they share a key property: they are all *periodic*. By periodic, we mean that the wave repeats itself at a regular time interval. This periodicity turns out to be integral to pitch perception.

```{r}
embed_image_with_audio(
  image = "images/sine-wave-frequency=240.png",
  audio = "audio/tone-frequency=240.wav",
  width = "400px",
  title = "An example sine wave."
)
```

We also covered the notion of 'frequency'. Frequency tells us the repetition rate of a periodic waveform, and is expressed in units of Hz. A frequency of 5 Hz means that the waveform repeats at a rate of 5 times per second.

```{r}
embed_image(
  image = "images/sine-wave-frequency=5.png",
  width = "400px",
  title = "A sine wave with a frequency of 5 Hz."
)
```

While frequency is a concrete, observable property in the outside world, pitch is something relatively intangible, present only in the mind. We define 'pitch' as the perceptual correlate of frequency; essentially, we are saying that "pitch is that perceptual quality of sound that derives from the underlying sound wave's frequency".Â 

As discussed in \@ref(foundations-of-acoustics), we can represent a given sound either in a *temporal* representation or in a *spectral* representation. In the temporal representation, we study the waveform, which tells us how pressure changes over time. In the spectral representation, we instead decompose the waveform into its constituent sine waves, and we study the frequencies and amplitudes of these sine waves. The process of converting from a temporal to a spectral representation is achieved using the mathematical technique of Fourier transformation.\

```{r}
embed_image(
  "images/waveforms-to-spectra.png",
  title = "Converting from temporal representations to spectral representations.",
  width = "100%"
)
```

The two main theories for human pitch perception correspond to these two different ways of representing sounds. We call these theories the *spectral* and *temporal* theories of pitch perception respectively.

## Spectral theory

According to the spectral theory, pitch perception depends fundamentally on a spectral analysis process that occurs within the *inner ear*, the deepest part of the ear. In mammals, the inner ear is encased in a bony structure called the *bony labyrinth*.

```{r}
embed_image(
  "images/inner-ear-location.png",
  title = "The location of the inner ear (black rectangle).",
  credit = '[Blausen.com staff](https://commons.wikimedia.org/wiki/File:Blausen_0329_EarAnatomy_InternalEar.png), [CC BY 3.0](https://creativecommons.org/licenses/by/3.0).',
  width = "100%"
)
```

The inner ear contains various structures involved in both sound perception and in orientation perception. The spectral analysis process occurs specifically in the *cochlea*, this coiled structure at the end of the inner ear.

```{r}
embed_image(
  "images/inner-ear-and-cochlea.png",
  title = "The location of the cochlea.",
  credit = "[Henry Vandyke Carter](https://commons.wikimedia.org/wiki/File:Gray920.png), public domain.",
  width = "100%"
)
```

It is easier to understand the cochlea if we imagine uncoiling it, as in the following diagram. The most important part of this diagram is the *basilar membrane*, a long structure that spans the length of the cochlea. At the base, the basilar membrane is thick and stiff, but at its apex, it is thin and mobile. As a result, the basilar membrane has different resonant properties along its length.

```{r}
embed_image(
  "images/basilar-membrane.png",
  title = "Schematic illustration of the basilar membrane.",
  width = "100%",
  credit = "[Kern A, Heid C, Steeb W-H, Stoop N, Stoop R, derivative work by Mike.lifeguard](https://commons.wikimedia.org/wiki/File:Schematic_uncoiled_cochlea.svg), [CC BY 2.5](https://creativecommons.org/licenses/by/2.5)."
)
```

Specifically, the base of the basilar membrane resonates at high frequencies, but as we move from the base to the apex, the resonant frequencies become lower and lower. As a result, when sound enters the cochlea, its different spectral components are translated into resonances at different locations along the basilar membrane. This spatial localisation of frequency components is called *tonotopy*. These different locations have their own connections to nerve cells, which communicate the resonances towards the brain, with these resonances already separated by spectral frequency.

The tonotopic nature of the basilar membrane is often described using the metaphor of *auditory filters*. In sound engineering, a filter is an object that selectively retains a subset of the frequencies in a frequency spectrum. For example, a low-pass filter only retains low frequencies, whereas a high-pass filter only retains high frequencies. When people talk about auditory filters in the context of the basilar membrane, they are talking about the way in which particular regions of the basilar membrane behaves somewhat like individual auditory filters. Specifically, a given region of the basilar membrane will only retain frequencies that are close to that region's characteristic frequency. The width of this filter is termed the 'critical band'.

As discussed previously, a complex tone has many spectral components. How would the brain merge these all together to form a coherent percept of pitch? It's thought that the brain uses a *template-matching process*, where the template corresponds to a set of equally spaced harmonics, each corresponding to integer multiples of a common fundamental frequency, with amplitude decreasing as harmonic number increases. This template could either be innate or learned through experience.

```{r}
embed_image(
  "images/harmonic-spectrum-2.svg",
  title = "Notional harmonic template.",
  width = "450px"
)
```

The brain would continually search the spectrum for patterns that matched this template; whenever it identifies such patterns, it 'merges' their harmonics into a single auditory percept, corresponding to the complex tone. This percept would have a pitch corresponding to the lowest harmonic in this template, corresponding to the fundamental frequency.

This spectral theory of pitch perception is sometimes referred to as 'place theory' or 'tonotopic theory', to emphasise the way in which different spectral components are localised to different places in the ear.

## Temporal theory

The temporal theory of pitch perception still relies on the mechanisms of the inner ear for translating air vibrations into neural impulses. However, it posits that pitch perception does not depend so much on transmitting the locations where the basilar membrane resonates, but rather depends on the temporal structure of the nerve impulses that are elicited by this resonance. In particular, the firing patterns of the nerve cells are known to entrain to the periodic motion of the basilar membrane, in what is called *phase locking*.

```{r}
embed_image(
  "images/phase-locking-intro.png",
  title = "Phase locking to an acoustic signal.",
  width = "450px",
  credit = "[Lvarnet](https://commons.wikimedia.org/wiki/File:Phase_locking_recorded_from_a_neuron_in_the_cochlear_nucleus.jpg), [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0)."
)
```

Though an individual nerve cell may not be able to fire fast enough to entrain to every wave cycle, multiple nerve cells stimulated together can simulate this effect, with different cells firing on different cycles. This idea that multiple nerve cells can work together to entrain to high frequencies is called *volley theory*. Through this mechanism, the brain can therefore access the main periodicities of the sound wave, represented as temporal firing patterns in the auditory nerve.

```{r}
embed_image(
  "images/volley-theory.png",
  title = "Illustration of volley theory.",
  width = "100%",
  credit = "[Rachel Candace Law](https://commons.wikimedia.org/wiki/File:Volley_Principle_of_Hearing.png), [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0)."
)
```

Suppose that this temporal information does reach the brain -- how does the brain then use this for pitch perception? The proposal is that the brain implements a version of *autocorrelation analysis*, which looks for time lags at which the signal correlates highly with itself. Time lags achieving high correlations are good candidates for the wave's fundamental frequency.

```{r}
embed_image(
  "images/autocorrelation-analysis.png",
  title = "Illustration of autocorrelation analysis.",
  info = "The brackets point to time lags at which the signal correlates highly with itself.",
  width = "500px",
)
```

There is a deep mathematical similarity between the autocorrelation analysis proposed here for the temporal theory and the Fourier analysis that was previously proposed for the spectral theory. We won't go into the mathematical details here. However, one thing to point out is that the autocorrelation method doesn't in general require the additional template-matching step that the Fourier method required.

Researchers have debated about spectral versus temporal mechanisms of pitch perception for almost a century, but remarkably we still don't really know the extent to which either mechanism contributes to pitch perception. Even with modern neuroscientific methods, it is very difficult to unpick the brain's implementation of pitch perception at a neural level, and so our understanding of this area relies in large part on combining results from many different behavioural psychoacoustics studies probing pitch perception in many different conditions. Currently it seems moderately plausible that both mechanisms contribute to pitch perception; in particular, it seems reasonable that the brain uses both mechanisms for frequencies up to about 2-4 kHz, at which point phase locking is thought to break down due to the neurochemical limitations of the interface between the basilar membrane and the auditory nerve [@Palmer1986-sd]. At higher frequencies the place-based spectral mechanism would then take over.

Interestingly, 2-4 kHz is about the limit for pitch production in conventional musical instruments; for example, the highest note produced by the piccolo is about 4 kHz. One might therefore speculate that *musical* pitch relies particularly on temporal mechanisms.

```{r}
embed_image(
  "images/piccolo.jpg",
  title = "Photo of a piccolo.",
  width = "100%",
  credit = "[Metropolitan Museum of Art](https://commons.wikimedia.org/wiki/File:Piccolo_MET_254852.jpg), [CC0](https://creativecommons.org/publicdomain/zero/1.0/)."
)
```

## Pitch intervals

The notion of *pitch interval* is exceptionally important in Western music, and in most known musical styles across the world. A pitch interval is defined as a particular frequency ratio ....

(simultaneous vs sequential) 

Suppose we play someone a pair of tones, with frequencies $f_1$ and $f_2$ respectively, and ask them to judge the 'distance' between the tones



many cultures see mnusic in terms of scales 

## Frequencies and note numbers




So, how exactly do these frequencies relate to the keys we see on the piano keyboard?

$$
\textrm{Pitch interval (octaves)} = \log_2\left(\frac{f_2}{f_1}\right)
$$  

$$
\textrm{Pitch interval (semitones)} = 12 \log_2\left(\frac{f_2}{f_1}\right)
$$

$$
\textrm{MIDI note} &=
  \textrm{ref. MIDI note } 
  + \textrm{pitch interval (semitones)}
$$

$$
\textrm{MIDI note number} = 
69 + 12 \log_2 \left( \frac{\textrm{frequency}}{440} \right)
$$

explain the mapping, give the equation.

## Relative pitch

Western listeners tend not to hear pitch in *absolute* terms; even highly trained musicians will struggle to name a given note played without additional contextual information. Instead, most Western listeners tend to hear pitch in *relative* terms, specifically in terms of the recognition of particular *frequency ratios*. For example, if a listener is played a pair of tones corresponding to the frequencies 555 Hz and 833 Hz respectively, they are unlikely to realise that the two tones correspond to a C\# and a G\#, but they are relatively likely to recognise that the two frequencies are related by a 3:2 ratio, corresponding to a perfect fifth.

Particular frequency ratios correspond to particular intervals from Western music theory. For example, the frequency ratio 2:1 corresponds to an octave.

Several such frequency ratios are listed in the table below:

| Interval | Col2 | Col3 |
|----------|------|------|
|          |      |      |
|          |      |      |
|          |      |      |

: Caption

Frequency ratios

perceptual identity transposition

## Pitch chroma

octave invariance

Western listeners seem to interpret pitch in terms of at least two essential properties: *height* and *chroma*. Let's consider each in term.

### Pitch height

Pitch height describes the sense in which musical pitches seem to be ordered from 'low' to high'. High pitches correspond to high frequencies, and low pitches correspond to low frequencies. Psychoacousticians have performed various studies to try and quantif

### Pitch chroma
