# Causality

## Correlation and causation

When two variables correlate significantly with each other, this is a sign that there is some kind of underlying *causal* connection. However, we must be very careful about how we identify the nature of that causal connection.

A classic example from the music psychology is the association between musical training and intelligence. Many studies have noted that, on average, individuals with greater levels of musical training tend to have higher levels of general intelligence, as measured for example by IQ tests [@Dos_Santos-Luiz2016-st; @Schellenberg2011-yo; @Glenn_Schellenberg2011-nq].

A popular explanation for this association is that musical training *causes* an individual to develop greater cognitive skills [@Rauscher2002-wg; @Hetland2000-tr; @Gardiner1996-gh; @Moreno2014-dx]. After all, playing music is a complex intellectual activity that loads on basic cognitive capacities such as attention, memory, and hand-eye coordination. If these cognitive capacities are anything like muscles, then training them should enhance them, with positive consequences for general intelligence.

An alternative explanation is that high intelligence predisposes individuals to persist with musical training. One way this could happen is if intelligent people tend to be more successful in the early stages of music learning, which encourages them to continue with the training process.

A third potential explanation is that neither musical training nor general intelligence causally affect each other, and instead there is some unnoticed third variable that drives both of them. For example, we know that different children grow up with different levels of household income. Perhaps having higher household income has two relevant effects here: (a) it makes the family more likely to pay for music lessons, and (b) it makes the family invest more money in the child's academic education, increasing their performance on intelligence tests as a result.

These kinds of causal dilemmas are common whenever a scientist works with an *observational* dataset. An observational dataset is a dataset collected solely by observing and measuring a given phenomenon. There are various statistical techniques out there (e.g. regression modelling, causal modelling) that can be helpful for interrogating such datasets, but all rely on certain assumptions, and it is difficult to get a definitive answer out of them. It seems strange to imagine nowadays, but it took decades for health organisations to be convinced that smoking had a causal effect on lung cancer incidence, despite the correlation between smoking and lung cancer being established long prior.

## Experimental manipulations

In practice, the scientist's most powerful tool for solving these kinds of causal problems tends to be *manipulation*. What happens here is that the scientist actively manipulates Variable A, and observes whether Variable B changes in response. If Variable B does change, then we have strong evidence that Variable A causally influences Variable B. If not, then we must think again.

### Independent and dependent variables

When conducting an experiment with a manipulation, it is conventional to classify the variables into two categories: *independent* and *dependent* variables. Independent variables are variables that the experimenter manipulates (Variable A in the example above). Dependent variables are variables that the experimenter measures without manipulating them directly (Variable B in the example above).

### Repeated measures and between-groups designs

Experimental manipulations generally fall into two categories: *repeated-measures* and *between-groups*. Let's consider each in turn.

In a *repeated-measures* design, we have a collection of participants, and we wish to examine the impact of a manipulation on these participants. Here the term 'manipulation' can be interpreted broadly. It could mean doing something literally to the participants --- for example giving them a cup of coffee --- but it could also mean doing something to the experimental setup that the participant experiences, for example changing the volume of the auditory stimuli. The defining characteristic of a repeated-measures design is that we expose each individual participant to multiple *levels* of the manipulation. Depending on the experiment, these levels could mean different things:

1.  Before or after an intervention, for example before or after a cup of coffee;
2.  Different categories of a discrete independent variable, for example running, walking, or sitting;
3.  Different values of a continuous independent variable, for example 33% volume, 49% volume, or 52% volume.

Sometimes it is not practical for the same subject to experience multiple levels of the same independent variable. In this case we conduct a *between-groups design*, where each participant only experiences only level of the independent variable. For the experimental manipulation to be considered valid, it is essential that the assignment of participants to independent variable levels be *randomised*. In principle, this could be done by rolling a die for each participant and choosing the value of the independent variable on the basis of the die roll; in practice researchers tend to use random number generators instead. Other methods (e.g. each participant choosing their own condition) *do not* qualify as proper manipulations, because the values of the independent variable will be affected by unknown pre-existing differences between the participants, which may have their own causal associations with the dependent variable.

It is possible to have multiple independent variables in the same experiment. Experiments with all repeated-measures variables or all between-groups variables are called repeated-measures and between-groups designs respectively; experiments with *both* repeated-measures and between-groups variables are called *mixed* designs.

In practice, repeated-measures designs tend to be considerably more powerful than between-groups designs. This is because repeated-measures are very good at accounting for individual differences between participants; even if one participant tends to score particularly low or particularly high on a dependent variable, this idiosyncrasy should apply equally across the different levels of the independent variable, so it can be controlled for when analysing the data. In contrast, in a between-groups design it is much harder to separate individual differences from the effects of the experimental manipulations; as a consequence, such designs can require many times more participants to achieve the same statistical reliability (see [this blog post](https://daniellakens.blogspot.com/2016/11/why-waithin-subject-designs-require-less.html) for an analysis). So, where possible, it is advisable to try and formulate studies as repeated-measures rather than between-groups designs.

One disadvantage of repeated-measures designs, though, is that they can be susceptible to *carry-over* *effects*. A carry-over effect is one where the identity of preceding conditions influences scores in the current condition. For example, suppose we are studying the effect of physical exercise on music listening, and we have three values of the independent variable: running, walking, and sitting. The effects of physical exercise on heart rate and body temperature can be fairly long-lasting. If we have the participant run for five minutes, then sit for five minutes, then walk for five minutes, their heart rate in the 'sit' condition is likely to be inflated by the fact that they were running in the previous condition. It's essential therefore in repeated-measures designs to ensure that the order of conditions is *balanced* between participants, rather than being the same for all participants. One way of achieving this is simply to randomise the order of conditions across participants. There also exist more sophisticated ways of achieving this, for example *Latin square designs*, which ensure that the order of conditions is *perfectly* balanced between participants, rather than just being balanced on average. These only become important for very small participant groups, and we won't consider them here.

### Case study: Schellenberg (2004)

@Schellenberg2004-zh addressed the aforementioned question of whether musical training causes improvements in general intelligence. The study used a sample group of 144 six-year-old children in a between-groups design. The children were randomly assigned to one of four types of 36-week extracurricular classes: keyboard lessons, voice lessons, drama lessons, or no lessons. The researchers administered a battery of cognitive tests to the children before and after the training period. On average, children in all groups increased in IQ over the time period, as would be expected due to maturation and education. However, children who took music lessons experienced a greater increase in IQ (\~ 7 points), as compared to children in the drama or no lessons conditions (\~ 4 points). The researchers concluded that musical training does indeed improve general intelligence (though note that this conclusion is controversial! see @Sala2020-hw for a recent meta-analysis disputing this and related studies).

## Conclusions

Experimental manipulations are a very valuable tool for identifying causal relationships. Unfortunately, however, they are not always practical to conduct. Some kinds of manipulations take too long to achieve in the context of a particular study, or are too expensive, or raise problematic ethical issues. In these cases observational studies may be the only way forward. Fortunately, there are still many interesting things that we can learn from such studies with the right kinds of statistical methods. We'll explore some of these in the next chapter.
